{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Classification with a BOW Naive Bayes Model\n",
    "\n",
    "Some parts of this are adapted from the Week 5 lab on Blackboard (marked as such in the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize = False\n",
    "remove_stopwords = False\n",
    "use_nltk_tokenizer = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_data = load_dataset(\"dair-ai/emotion\", split=\"train\")\n",
    "test_data = load_dataset(\"dair-ai/emotion\", split=\"test\")\n",
    "# This is a HuggingFace dataset\n",
    "print(train_data.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of this code is adapted from the lab\n",
    "stop_words = list(stopwords.words('english'))\n",
    "all_words = []\n",
    "for example in train_data:\n",
    "    if use_nltk_tokenizer:\n",
    "        all_words.extend(word_tokenize(example[\"text\"]))\n",
    "    else:\n",
    "        all_words.extend(example[\"text\"].split())\n",
    "\n",
    "if lemmatize:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    freqdist = nltk.FreqDist(lemmatizer.lemmatize(w.lower()) for w in all_words)\n",
    "else:\n",
    "    freqdist = nltk.FreqDist(w.lower() for w in all_words)\n",
    "\n",
    "\n",
    "top_words = set(list(freqdist)[:2000])\n",
    "\n",
    "if remove_stopwords:\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    top_words = list(top_words.difference(stop_words))\n",
    "\n",
    "print(\"Using {} top words as features\".format(len(top_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from the lab\n",
    "def document_features(document, top_words):\n",
    "    if use_nltk_tokenizer:\n",
    "        document = word_tokenize(document)\n",
    "    else:\n",
    "        document = document.split()\n",
    "    if lemmatize:\n",
    "        document = [lemmatizer.lemmatize(w) for w in document]\n",
    "    doc_words = set(document)\n",
    "    features = {}\n",
    "    for word in top_words:\n",
    "        features['contains({})'.format(word)] = (word in doc_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of this code is adapted from the lab\n",
    "train_documents = [(example[\"text\"], example[\"label\"]) for example in train_data]\n",
    "random.shuffle(train_documents)\n",
    "test_documents = [(example[\"text\"], example[\"label\"]) for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of this code is adapted from the lab\n",
    "train_set = [(document_features(document=d, top_words=top_words), label) for d, label in train_documents]\n",
    "test_set = [(document_features(document=d, top_words=top_words), label) for d, label in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: i feel reassured that i am dealing with my diet in the right way and that all is good, LABEL: 1, MODEL DECISION: 1\n"
     ]
    }
   ],
   "source": [
    "# Part of this code is adapted from the lab\n",
    "test_doc = test_documents[42]\n",
    "decision = classifier.classify(document_features(document=test_doc[0],\n",
    "top_words=top_words))\n",
    "print(\"ID: %s, LABEL: %s, MODEL DECISION: %s\" % (test_doc[0],\n",
    "test_doc[1], decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(amazed) = True                5 : 0      =    361.1 : 1.0\n",
      "       contains(curious) = True                5 : 0      =    290.5 : 1.0\n",
      "       contains(shocked) = True                5 : 0      =    247.1 : 1.0\n",
      "         contains(dazed) = True                5 : 0      =    176.5 : 1.0\n",
      "        contains(caring) = True                2 : 1      =    168.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "  \"sadness\": 0,\n",
    "  \"joy\": 1,\n",
    "  \"love\": 2,\n",
    "  \"anger\": 3,\n",
    "  \"fear\": 4,\n",
    "  \"surprise\": 5\n",
    "}\n",
    "emotions = [ \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness   0.881739  0.872633  0.877163       581\n",
      "         joy   0.868966  0.906475  0.887324       695\n",
      "        love   0.639241  0.635220  0.637224       159\n",
      "       anger   0.848485  0.814545  0.831169       275\n",
      "        fear   0.791855  0.781250  0.786517       224\n",
      "    surprise   0.561404  0.484848  0.520325        66\n",
      "\n",
      "    accuracy                       0.834500      2000\n",
      "   macro avg   0.765281  0.749162  0.756620      2000\n",
      "weighted avg   0.832811  0.834500  0.833366      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "for item in test_documents:\n",
    "    y_pred = classifier.classify(document_features(document=item[0],\n",
    "        top_words=top_words))\n",
    "    all_preds.append(y_pred)\n",
    "    all_true.append(item[1])\n",
    "print(classification_report(all_true, all_preds, target_names=label2int.keys(), digits=len(emotions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.006106706663809728, 1: 0.007738206227857543, 2: 0.008045977011494253, 3: 0.004861111111111111, 4: 0.00696594427244582, 5: 0.004363001745200698}\n"
     ]
    }
   ],
   "source": [
    "def informative_per_class(c1:int, c2:int):\n",
    "    features_d = {}\n",
    "    for (label, fname), probdist in classifier._feature_probdist.items():\n",
    "        if \"(sound)\" in fname:\n",
    "            print(label, probdist.prob(True))\n",
    "        if label == c1:\n",
    "            if fname not in features_d:\n",
    "                features_d[fname] = {c1:None, c2:None}\n",
    "            features_d[fname][c1] = probdist.prob(True)\n",
    "        elif label == c2:\n",
    "            if fname not in features_d:\n",
    "                features_d[fname] = {c1:None, c2:None}\n",
    "            features_d[fname][c2] = probdist.prob(True)\n",
    "    features = [(fname, class_d[c1]/class_d[c2]) for fname, class_d in features_d.items()]\n",
    "    features.sort(key=lambda x:x[1], reverse=True)\n",
    "    print(features[:5])\n",
    "    print(features[-5:])\n",
    "    return features\n",
    "\n",
    "def get_features_for_tokens(tokens, include_absent = True):\n",
    "    odds = {f: 1 for f in range(len(emotions))}\n",
    "    for token in tokens:\n",
    "        for (label, fname), probdist in classifier._feature_probdist.items():\n",
    "            if f\"({token})\" in fname:\n",
    "                odds[label] *= probdist.prob(True)\n",
    "            else:\n",
    "                if include_absent:\n",
    "                    odds[label] *= probdist.prob(False)\n",
    "    return odds      \n",
    "\n",
    "#informative_per_class(1, 2)\n",
    "print(get_features_for_tokens([\"great\"], include_absent = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bow_misclassified.txt\", \"w\") as f:\n",
    "    for i, item in enumerate(test_documents):\n",
    "        y_pred = classifier.classify(document_features(document=item[0],\n",
    "            top_words=top_words))\n",
    "        if y_pred != item[1]:\n",
    "            f.write(f\"{test_data[i][\"text\"]}, pred: {y_pred}, true: {item[1]}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 9.40k/9.40k [00:00<00:00, 9.48MB/s]\n",
      "Downloading data: 100%|██████████| 2.77M/2.77M [00:01<00:00, 1.87MB/s]\n",
      "Downloading data: 100%|██████████| 350k/350k [00:00<00:00, 461kB/s]\n",
      "Downloading data: 100%|██████████| 347k/347k [00:00<00:00, 476kB/s]\n",
      "Generating train split: 100%|██████████| 43410/43410 [00:00<00:00, 419632.43 examples/s]\n",
      "Generating validation split: 100%|██████████| 5426/5426 [00:00<00:00, 493148.14 examples/s]\n",
      "Generating test split: 100%|██████████| 5427/5427 [00:00<00:00, 493452.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 7894 entries\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness   0.266883  0.682504  0.383718      1326\n",
      "         joy   0.353927  0.704656  0.471190      1439\n",
      "        love   0.614880  0.140010  0.228084      2007\n",
      "       anger   0.484286  0.220273  0.302814      1539\n",
      "        fear   0.447761  0.214669  0.290206       559\n",
      "    surprise   0.751174  0.156250  0.258690      1024\n",
      "\n",
      "    accuracy                       0.357107      7894\n",
      "   macro avg   0.486485  0.353060  0.322450      7894\n",
      "weighted avg   0.489241  0.357107  0.321481      7894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data = load_dataset(\"go_emotions\", \"simplified\")\n",
    "go_documents = []\n",
    "# surprise: 26, sadness 25, joy 17, love 18, anger 2, fear 14\n",
    "mapping_dict = {25:0, 17:1, 18:2, 2:3, 14:4, 26:5}\n",
    "for ex in data['train']:\n",
    "    labels = set(ex['labels']).intersection(mapping_dict.keys())\n",
    "    if labels:\n",
    "        text = re.sub(r'[^\\w\\s]', '', ex['text'].lower()) # remove punctuation, make lowercase\n",
    "        go_documents.append((text, mapping_dict[list(labels)[0]]))\n",
    "print(f\"Dataset loaded: {len(go_documents)} entries\")\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "for item in go_documents:\n",
    "    y_pred = classifier.classify(document_features(document=item[0],\n",
    "        top_words=top_words))\n",
    "    all_preds.append(y_pred)\n",
    "    all_true.append(item[1])\n",
    "print(classification_report(all_true, all_preds, target_names=label2int.keys(), digits=len(emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\ursus\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\dair-ai--emotion\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd (last modified on Fri Mar 29 16:07:52 2024) since it couldn't be found locally at dair-ai/emotion, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\ursus\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\dair-ai--emotion\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd (last modified on Fri Mar 29 16:07:52 2024) since it couldn't be found locally at dair-ai/emotion, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\ursus\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\dair-ai--emotion\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd (last modified on Fri Mar 29 16:07:52 2024) since it couldn't be found locally at dair-ai/emotion, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4666, 1: 5362, 2: 1304, 3: 2159, 4: 1937, 5: 572}\n",
      "{0: 550, 1: 704, 2: 178, 3: 275, 4: 212, 5: 81}\n",
      "{0: 581, 1: 695, 2: 159, 3: 275, 4: 224, 5: 66}\n"
     ]
    }
   ],
   "source": [
    "tr = load_dataset(\"dair-ai/emotion\", split=\"train\")['label']\n",
    "val = load_dataset(\"dair-ai/emotion\", split=\"validation\")['label']\n",
    "te = load_dataset(\"dair-ai/emotion\", split=\"test\")['label']\n",
    "\n",
    "for split in [tr, val, te]:\n",
    "    classes = {n:0 for n in range(len(emotions))}\n",
    "    for instance in split:\n",
    "        classes[instance] += 1\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "rnn = open(\"misclass_rnn.txt\", \"r\")\n",
    "bow = open(\"bow_misclassified.txt\", \"r\")\n",
    "\n",
    "counter = 0\n",
    "rnn_sents = set()\n",
    "for line in rnn:\n",
    "    rnn_sents.add(line.split(\" //\")[0])\n",
    "for line in bow:\n",
    "    if line.split(\", pred\")[0] in rnn_sents:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "#print(len(rnn.readlines()))\n",
    "#print(len(bow.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
